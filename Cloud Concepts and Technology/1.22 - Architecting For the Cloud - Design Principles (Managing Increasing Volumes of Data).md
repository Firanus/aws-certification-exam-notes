# 1.22 - Architecting For the Cloud - Design Principles (Managing Increasing Volumes of Data)

In the age of big data, many organizations are finding that traditional data storage and analytics tools are no longer sufficient. For that reason, many organisations are moving to a data lake architecture.

A **data lake** is an architectural approach that lets you store massive amount of dta in a central location so that it can be readily available for categorization, processing, analysis and consumption by diverse groups in your organisation.

Since you store data as-is, you don't need to convert it into a pre-defined schema, and you don't need to know the kinds of questions you want to ask in advance. This lets you pick the best technology for each specific analytical requirement.

For more info, see the [Building a Data Lake with AWS](https://d0.awsstatic.com/whitepapers/Storage/data-lake-on-aws.pdf) whitepaper.